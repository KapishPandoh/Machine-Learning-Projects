{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset :** [Kaggle Machine Learning Fake News Dataset](https://www.kaggle.com/c/fake-news/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset :** [Kaggle Machine Learning Fake News Dataset](https://www.kaggle.com/c/fake-news/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`label` : a label that marks the article as potentially unreliable\n",
    "- **1** , unreliable\n",
    "- **0** , reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, title, author, text, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0.000000\n",
       "title     0.026827\n",
       "author    0.094087\n",
       "text      0.001875\n",
       "label     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[ data['title'].notna() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20242, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0.000000\n",
       "title     0.000000\n",
       "author    0.096680\n",
       "text      0.001927\n",
       "label     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps   = PorterStemmer()\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "for i in range(0 ,len(data)) :\n",
    "    \n",
    "    review = re.sub('[^a-zA-Z]' ,\" \",data['title'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word)   for word in review   if not word in stop]\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    data['title'][i] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        hous dem aid even see comey letter jason chaff...\n",
       "1          flynn hillari clinton big woman campu breitbart\n",
       "2                                     truth might get fire\n",
       "3                 civilian kill singl us airstrik identifi\n",
       "4        iranian woman jail fiction unpublish stori wom...\n",
       "                               ...                        \n",
       "20237            rapper trump poster child white supremaci\n",
       "20238      n f l playoff schedul matchup odd new york time\n",
       "20239    maci said receiv takeov approach hudson bay ne...\n",
       "20240             nato russia hold parallel exercis balkan\n",
       "20241                                          keep f aliv\n",
       "Name: title, Length: 20242, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,'title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Vectorizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:,'title']\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer( max_features=5000 ,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer( max_features=4000 ,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_Model(X,y,vectorizer,model):\n",
    "    \n",
    "    X_train ,X_test ,y_train ,y_test = train_test_split( \n",
    "                                                          X , \n",
    "                                                          y ,\n",
    "                                                          test_size=0.2 ,\n",
    "                                                          random_state=0\n",
    "                                                        )\n",
    "    \n",
    "    X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "    X_test  = vectorizer.transform(X_test).toarray()\n",
    "    \n",
    "    vec = \"\"\n",
    "    if(vectorizer==cv):\n",
    "        vec = \"CountVectorizer\"\n",
    "    else:\n",
    "        vec = \"TfidfVectorizer\"\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\"*50)\n",
    "    \n",
    "    print(\"\\nModel      : \",model)\n",
    "    print(\"\\nVectorizer : \",vec)\n",
    "    \n",
    "#     param = {\n",
    "#               'alpha':np.arange(0,1,0.1)\n",
    "#             }\n",
    "    \n",
    "#     model = GridSearchCV(\n",
    "#                           model ,\n",
    "#                           param ,\n",
    "#                           cv=2\n",
    "#                         )\n",
    "    \n",
    "    model  = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "#     print(\"Best Parameter : \",model.best_params_)\n",
    "    \n",
    "    acc = accuracy_score(y_test ,y_pred)\n",
    "    print(\"\\nAccuracy   : \",acc)\n",
    "    \n",
    "\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    print(\"\\nConfusion Matrix , \\n\",cm)\n",
    "    \n",
    "    print(\"\\nClassification Report ,\\n\" ,classification_report(y_test,y_pred),\"\\n\")\n",
    "    \n",
    "    print(\"*\"*50)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. MultinomialNB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Model      :  MultinomialNB()\n",
      "\n",
      "Vectorizer :  CountVectorizer\n",
      "\n",
      "Accuracy   :  0.8970116078043961\n",
      "\n",
      "Confusion Matrix , \n",
      " [[1851  216]\n",
      " [ 201 1781]]\n",
      "\n",
      "Classification Report ,\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      2067\n",
      "           1       0.89      0.90      0.90      1982\n",
      "\n",
      "    accuracy                           0.90      4049\n",
      "   macro avg       0.90      0.90      0.90      4049\n",
      "weighted avg       0.90      0.90      0.90      4049\n",
      " \n",
      "\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prepare_Model(X,y,cv,nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Model      :  MultinomialNB()\n",
      "\n",
      "Vectorizer :  TfidfVectorizer\n",
      "\n",
      "Accuracy   :  0.8794764139293653\n",
      "\n",
      "Confusion Matrix , \n",
      " [[1912  155]\n",
      " [ 333 1649]]\n",
      "\n",
      "Classification Report ,\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      2067\n",
      "           1       0.91      0.83      0.87      1982\n",
      "\n",
      "    accuracy                           0.88      4049\n",
      "   macro avg       0.88      0.88      0.88      4049\n",
      "weighted avg       0.88      0.88      0.88      4049\n",
      " \n",
      "\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prepare_Model(X,y,tfidf,nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Passive Aggressive Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = PassiveAggressiveClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Model      :  PassiveAggressiveClassifier()\n",
      "\n",
      "Vectorizer :  CountVectorizer\n",
      "\n",
      "Accuracy   :  0.9192393183502099\n",
      "\n",
      "Confusion Matrix , \n",
      " [[1905  162]\n",
      " [ 165 1817]]\n",
      "\n",
      "Classification Report ,\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2067\n",
      "           1       0.92      0.92      0.92      1982\n",
      "\n",
      "    accuracy                           0.92      4049\n",
      "   macro avg       0.92      0.92      0.92      4049\n",
      "weighted avg       0.92      0.92      0.92      4049\n",
      " \n",
      "\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prepare_Model(X,y,cv,pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Model      :  PassiveAggressiveClassifier()\n",
      "\n",
      "Vectorizer :  TfidfVectorizer\n",
      "\n",
      "Accuracy   :  0.9189923437885897\n",
      "\n",
      "Confusion Matrix , \n",
      " [[1860  207]\n",
      " [ 121 1861]]\n",
      "\n",
      "Classification Report ,\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      2067\n",
      "           1       0.90      0.94      0.92      1982\n",
      "\n",
      "    accuracy                           0.92      4049\n",
      "   macro avg       0.92      0.92      0.92      4049\n",
      "weighted avg       0.92      0.92      0.92      4049\n",
      " \n",
      "\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prepare_Model(X,y,tfidf,pa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
